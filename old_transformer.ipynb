{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transformer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOJBjDMTcXCsqTubO0A8uh3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHn6K0u3-2lF",
        "outputId": "ca713793-e58d-4eab-91c6-ad826ba89897"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ]
        }
      ],
      "source": [
        "%pylab inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "import zipfile\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as f\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import vocab\n",
        "\n",
        "\n",
        "from functools import partial,reduce\n",
        "from tqdm import tqdm, trange\n",
        "tqdm = partial(tqdm, position=0, leave=True)\n",
        "trange = partial(trange, position=0, leave=True)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "DEVICE = 'cuda:0'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsjnJWPI3u47",
        "outputId": "11968709-1563-45a6-d6b2-3c21ba32ff21"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Jul 21 14:49:02 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    27W / 250W |      2MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip'\n",
        "\n",
        "r = requests.get(url)\n",
        "\n",
        "ul = url.split('/')\n",
        "name = ul[len(ul) - 1]\n",
        "\n",
        "with open(name, 'wb') as file:\n",
        "  file.write(r.content)\n",
        "\n",
        "with zipfile.ZipFile(name, \"r\") as zip_ref:\n",
        "  zip_ref.extractall(\"./\")\n",
        "\n",
        "!mv 'cornell movie-dialogs corpus' 'data'\n",
        "!ls 'data'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SN_cyVT6eQQM",
        "outputId": "3cefe78d-5a28-491e-e1de-af2dc7ecd41d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chameleons.pdf\t\t       movie_lines.txt\t\t  README.txt\n",
            "movie_characters_metadata.txt  movie_titles_metadata.txt\n",
            "movie_conversations.txt        raw_script_urls.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "V_jfwwVQKw-o"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FIELD_SPLITTER = '+++$+++'\n",
        "\n",
        "MAX_SAMPLES = 50000\n",
        "MAX_LENGTH = 40\n",
        "\n",
        "UNK_TOKEN = '<unk>'\n",
        "PAD_TOKEN = '<PAD>'\n",
        "BOS_TOKEN = '<BOS>'\n",
        "EOS_TOKEN = '<EOS>'\n",
        "\n",
        "UNK_TOKEN_IND = 0\n",
        "PAD_TOKEN_IND = 1\n",
        "BOS_TOKEN_IND = 2\n",
        "EOS_TOKEN_IND = 3\n",
        "\n",
        "BATCH = 128"
      ],
      "metadata": {
        "id": "Kx8U5FhayR-T"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PW9kkcKGvkht"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_sentence(sentence):\n",
        "    sentence = sentence.lower().strip()\n",
        "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "    sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence)\n",
        "    sentence = sentence.strip()\n",
        "    return sentence"
      ],
      "metadata": {
        "id": "-FmVEHllv777"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_transform = lambda x, voc, tokenizer: [voc['<BOS>']] + [voc[token] for token in tokenizer(x)] + [voc['<EOS>']]"
      ],
      "metadata": {
        "id": "5xjiwfyZwZbt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this is terrible as fuck because torchtext is terrible as fuck\n",
        "def load_conversations(path_to_movie_lines, path_to_movie_conversations):\n",
        "    id2line = {}\n",
        "    with open(path_to_movie_lines, errors='ignore') as file:\n",
        "        lines = file.readlines()\n",
        "        for line in lines:\n",
        "            parts = line.replace('\\n', '').split(' +++$+++ ')\n",
        "            id2line[parts[0]] = parts[4]\n",
        "\n",
        "    inputs, outputs = [], []\n",
        "    with open(path_to_movie_conversations, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "        for line in lines:\n",
        "            parts = line.replace('\\n', '').split(' +++$+++ ')\n",
        "            conversation = [line[1:-1] for line in parts[3][1:-1].split(', ')]\n",
        "            for i in range(len(conversation) - 1):\n",
        "                inputs.append(preprocess_sentence(id2line[conversation[i]]))\n",
        "                outputs.append(preprocess_sentence(id2line[conversation[i + 1]]))\n",
        "                if len(inputs) >= MAX_SAMPLES:\n",
        "                    return inputs, outputs\n",
        "    return inputs, outputs\n"
      ],
      "metadata": {
        "id": "-sijVHLArNQJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataloader(path_to_movie_lines,\n",
        "                   path_to_movie_conversations):\n",
        "    questions, answers = load_conversations(path_to_movie_lines, path_to_movie_conversations)\n",
        "\n",
        "    tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "    counter = Counter()\n",
        "    for sent in questions + answers:\n",
        "        counter.update(tokenizer(sent))\n",
        "\n",
        "    voc = vocab(counter)\n",
        "    voc.insert_token(token=UNK_TOKEN, index=UNK_TOKEN_IND)\n",
        "    voc.set_default_index(index=UNK_TOKEN_IND)\n",
        "    voc.insert_token(token=PAD_TOKEN, index=PAD_TOKEN_IND)\n",
        "    voc.insert_token(token=BOS_TOKEN, index=BOS_TOKEN_IND)\n",
        "    voc.insert_token(token=EOS_TOKEN, index=EOS_TOKEN_IND)\n",
        "\n",
        "    q_tokenized = [text_transform(t, voc, tokenizer) for t in questions]\n",
        "    a_tokenized = [text_transform(t, voc, tokenizer) for t in answers]\n",
        "\n",
        "    import tensorflow as tf # todo\n",
        "    q_padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "        q_tokenized, maxlen=MAX_LENGTH, padding='post', value=1.0)\n",
        "\n",
        "    a_padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "        a_tokenized, maxlen=MAX_LENGTH, padding='post', value=1.0)\n",
        "\n",
        "    print(\"Vocab len\", len(voc))\n",
        "\n",
        "    dataloader = DataLoader(\n",
        "        list(\n",
        "            zip(\n",
        "                  q_padded.astype(np.float32),\n",
        "                  a_padded.astype(np.float32),\n",
        "                )\n",
        "            ),\n",
        "            batch_size=BATCH,\n",
        "            shuffle=False,\n",
        "    )\n",
        "\n",
        "    print(voc)\n",
        "    torch.save(voc, 'vocab')\n",
        "\n",
        "    return dataloader, text_transform, voc\n"
      ],
      "metadata": {
        "id": "dblp_TVLqvav"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "e3T8xN1yxmyc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines_path = 'data/movie_lines.txt'\n",
        "conversations_path = 'data/movie_conversations.txt'    \n",
        "\n",
        "dataloader, text_transform, voc = get_dataloader(lines_path,\n",
        "                                                 conversations_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e42tdLcayovn",
        "outputId": "cdef29f5-6113-4402-8e85-4b360a4eefe6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab len 23068\n",
            "Vocab()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_sample = None\n",
        "\n",
        "for i,x in enumerate(dataloader):\n",
        "  if i > 1: break\n",
        "  print(x[0].shape)\n",
        "  test_sample = x[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMyWFI7N3VVf",
        "outputId": "a2085d95-2361-4a94-b63e-2fbc055c713a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 40])\n",
            "torch.Size([128, 40])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OG_PUCipfDAT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://arxiv.org/pdf/1706.03762.pdf\n",
        "def sdpa_attention(q, k, v):\n",
        "    d = torch.sqrt(torch.tensor(k.shape[len(k.shape) - 1]))\n",
        "    scales = torch.matmul(q, k) / d\n",
        "    # mask?\n",
        "    weights = f.softmax(scales, dim=-1)\n",
        "    res = torch.matmul(weights, v)\n",
        "    return res\n",
        "    "
      ],
      "metadata": {
        "id": "Iajk3iU8hKlB"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiheadAttention(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MultiheadAttention, self).__init__()\n",
        "\n",
        "    self.V = nn.Linear(1, 1)\n",
        "    self.K = nn.Linear(1, 1)\n",
        "    self.Q = nn.Linear(1, 1)\n",
        "    self.O = nn.Linear(1, 1)\n",
        "\n",
        "  def forward(self, q, k, v):\n",
        "    q = self.Q(q)\n",
        "    k = self.Q(k)\n",
        "    v = self.Q(v)\n",
        "\n",
        "    a = sdpa_attention(q, k, v)\n",
        "    o = self.O(a)\n",
        "\n",
        "    return o\n"
      ],
      "metadata": {
        "id": "Ic6e2QJcHlqj"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
        "class PositionalEncoding1(nn.Module):\n",
        "    def __init__(self, vocab_len, dropout=0.1):\n",
        "      super(PositionalEncoding, self).__init__()\n",
        "      self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "      pe = torch.zeros(MAX_LENGTH, vocab_len)\n",
        "      position = torch.arange(0, MAX_LENGTH, dtype=torch.float).unsqueeze(1)\n",
        "      div_term = torch.exp(torch.arange(0, vocab_len, 2).float() *\n",
        "                           -(torch.log(torch.tensor(10000.0)).item() / vocab_len))\n",
        "      pe[:, 0::2] = torch.sin(position * div_term)\n",
        "      pe[:, 1::2] = torch.cos(position * div_term)\n",
        "      pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "      self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "      y = self.pe[:x.size(0), :]\n",
        "      print('Y SHAPE', y.shape)\n",
        "      print('X SHAPE', x.shape)\n",
        "      x = x + y\n",
        "      return self.dropout(x)"
      ],
      "metadata": {
        "id": "YImpb8ymHlsy"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xcvxNbhgfh3S"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_sample.shape)\n",
        "print(test_sample.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_FMbHcG3-e-",
        "outputId": "b2b0f273-b8bd-4922-e037-ac905ccee4ff"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 40])\n",
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "z6jeVikoDhio"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "  def __init__(self, vocab_len, embed_dim=64):\n",
        "    super(Transformer, self).__init__()\n",
        "    self.attention = MultiheadAttention()\n",
        "    self.norm = nn.LayerNorm(embed_dim)\n",
        "    self.lin = nn.Linear(embed_dim, embed_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.norm(x + self.attention(x, x, x))\n",
        "    x = self.norm(x + self.lin(x))\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "QfkMe8hL0oi7"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://medium.com/the-dl/transformers-from-scratch-in-pytorch-8777e346ca51\n",
        "def positional_encoding(seq_len, vocab_len):\n",
        "    pos = torch.arange(seq_len, dtype=torch.float, device=DEVICE).reshape(1, -1, 1)\n",
        "    dim = torch.arange(vocab_len, dtype=torch.float, device=DEVICE).reshape(1, 1, -1)\n",
        "    phase = pos / (1e4 ** (dim // vocab_len))\n",
        "\n",
        "    return torch.where(dim.long() % 2 == 0, torch.sin(phase), torch.cos(phase))"
      ],
      "metadata": {
        "id": "Jxr4MUuSKxHR"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self, vocab_len, emb_dim, enc_size, dec_size, inp_features, nhead):\n",
        "    super(Model, self).__init__()\n",
        "    self.vocab_len = vocab_len\n",
        "    self.emb_dim = emb_dim\n",
        "    self.inp_features = inp_features\n",
        "    \n",
        "    # self.p_encoding = PositionalEncoding(vocab_len)\n",
        "    self.embedding = nn.Embedding(vocab_len, emb_dim)\n",
        "\n",
        "    self.encoder = nn.Sequential(\n",
        "      *[nn.TransformerEncoderLayer(inp_features, nhead) for _ in range(enc_size)]\n",
        "    )\n",
        "    self.decoder = nn.Sequential(\n",
        "      *[nn.TransformerDecoderLayer(inp_features, nhead) for _ in range(dec_size)]\n",
        "    )\n",
        "\n",
        "    self.lin = nn.Linear(inp_features, inp_features)\n",
        "\n",
        "  \n",
        "  def forward(self, x, y):\n",
        "    x = self.embedding(x.int())\n",
        "    e_enc = positional_encoding(x.shape[1], x.shape[2])\n",
        "    x += e_enc\n",
        "    x = self.encoder(x)\n",
        "\n",
        "    # d_enc = positional_encoding(y.shape[0], y.shape[1])\n",
        "    # y = y.reshape(1, y.shape[0], y.shape[1])\n",
        "    print('\\nY SHAPE', y.shape)\n",
        "    print('\\n ENC SHAPE', e_enc.shape)\n",
        "    y += e_enc\n",
        "    print('BEFORE')\n",
        "    y = self.decoder(y, x)\n",
        "    print('AFTER')\n",
        "    y = torch.softmax(self.lin(y), dim=-1)\n",
        "\n",
        "    return y\n"
      ],
      "metadata": {
        "id": "CViIXC71HMH-"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb_dim = 200\n",
        "num_heads = 8\n",
        "enc_size = 1\n",
        "dec_size = 1\n",
        "\n",
        "model = Model(len(voc), emb_dim, enc_size, dec_size, emb_dim, num_heads).to(DEVICE)"
      ],
      "metadata": {
        "id": "wi7GRvfpevfS"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 1\n",
        "losses = []\n",
        "\n",
        "optimizer = optim.Adam(params=model.parameters(), lr=0.001)\n",
        "loss_fn = nn.NLLLoss()"
      ],
      "metadata": {
        "id": "lKZsejM8kabv"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in trange(EPOCHS):\n",
        "  for i, data in tqdm(enumerate(dataloader)):\n",
        "    i_seq, answ = data[0].to(DEVICE), data[1].to(DEVICE)\n",
        "    print()\n",
        "\n",
        "    out = model(i_seq) # todo\n",
        "    print(out.shape)\n",
        "\n",
        "    break"
      ],
      "metadata": {
        "id": "QtVP3qoOKxRU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "outputId": "b9f84bb4-90f0-4866-ad39-fbce8c8d50ee"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  \"\"\"\n",
            "0it [00:00, ?it/s]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Y SHAPE torch.Size([1, 128, 40])\n",
            "\n",
            " ENC SHAPE torch.Size([1, 128, 40])\n",
            "BEFORE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-114-e2ad3d88b464>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mi_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-111-d33bb82e3893>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0md_enc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'BEFORE'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AFTER'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: forward() takes 2 positional arguments but 3 were given"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OBqyF0NMSaga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(len(losses)), losses, 'b', label='Loss') plt.title('Losses')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "y4GSVA0xKxVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = 'test'\n",
        "\n",
        "q_tr = text_transform(query, voc, get_tokenizer('basic_english'))\n",
        "import tensorflow as tf\n",
        "q_p = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    [q_tr],\n",
        "    maxlen=MAX_LENGTH,\n",
        "    padding='post',\n",
        "    value=1.0\n",
        ")\n",
        "q_t = torch.Tensor(q_p).float().to(DEVICE)\n",
        "\n",
        "\n",
        "enc = encoder(q_t)\n",
        "dec, _ = decoder(enc)\n",
        "\n",
        "print(dec.int())\n",
        "\n",
        "tokens = [t.int().item() for t in dec[0]]\n",
        "words = voc.get_itos()\n",
        "result = ' '.join(list(filter(lambda w: '<' not in w and '>' not in w, [words[t] for t in tokens])))\n",
        "print('\\n\\n')\n",
        "print(result)\n",
        "\n"
      ],
      "metadata": {
        "id": "s1cpwVbSKxZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Up2jkK36zGAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xrr5i0IpzGCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LGWG3mbzzGEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Mum903TXzGHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LfUhnHL_Kxcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ddwvBDsnKxf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tail -n 10 data/movie_conversations.txt "
      ],
      "metadata": {
        "id": "4kVqD08vKxjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls data"
      ],
      "metadata": {
        "id": "zKWhBqLmKxoL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat data/README.txt"
      ],
      "metadata": {
        "id": "mm4in0NdubQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # trash\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# def preprocess(x):\n",
        "#   x_no_new = x.replace('\\n', '')\n",
        "#   text = x_no_new.split(FIELD_SPLITTER).pop()\n",
        "#   embedding = g_vectors.get_vecs_by_tokens(tokenizer(text), lower_case_backup=True)\n",
        "#   return embedding\n",
        "\n",
        "# tokenizer = get_tokenizer('basic_english')\n",
        "# g_vectors = GloVe(name='840B')\n",
        "# g_vocab = vocab(g_vectors.stoi)\n",
        "\n",
        "\n",
        "# train_iter = tt.data.BucketIterator(\n",
        "#   dataset=train_obj,\n",
        "#   batch_size = 2,\n",
        "#   sort_key=lambda x: len(x.review),\n",
        "#   shuffle=True,\n",
        "#   device=DEVICE\n",
        "# )\n",
        "\n",
        "# trainloader = torch.utils.data.DataLoader(\n",
        "# \t,\n",
        "# \tbatch_size=BATCH,\n",
        "# \tnum_workers=12,\n",
        "# \tshuffle=True\n",
        "# )"
      ],
      "metadata": {
        "id": "UBDoHXDJsqu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# embeddings = global_vectors.get_vecs_by_tokens(tokenizer(\"Hello, How are you?\"),\n",
        "#                                                lower_case_backup=True)\n",
        "# embeddings\n",
        "# \n",
        "# \n",
        "# \n",
        "# def batch(iterable, size):\n",
        "#     from itertools import chain, islice\n",
        "#     iterator = iter(iterable)\n",
        "#     for first in iterator:\n",
        "#         yield list(chain([first], islice(iterator, size - 1)))"
      ],
      "metadata": {
        "id": "DRxfxpjQsrTJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}